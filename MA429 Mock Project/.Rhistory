x[y==1,]
plot(x, col=(3-y))
plot(x)
help.start()
dat=data.frame(x=x, y=as.factor(y))
svmfit=svm(y~., data=dat, kernel="linear", cost=10,scale=FALSE)
plot(svmfit, dat)
svmfit$index
summary(svmfit)
svmfit=svm(y~., data=dat, kernel="linear", cost=0.1,scale=FALSE)
install.packages("e1071")
library(e1071)
set.seed(1)
x=matrix(rnorm(20*2), ncol=2)
y=c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,] + 1
plot(x, col=(3-y))
dat=data.frame(x=x, y=as.factor(y))
svmfit=svm(y~., data=dat, kernel="linear", cost=10,scale=FALSE)
plot(svmfit, dat)
svmfit$index
summary(svmfit)
svmfit=svm(y~., data=dat, kernel="linear", cost=0.1,scale=FALSE)
plot(svmfit, dat)
svmfit$index
set.seed(1)
tune.out=tune(svm,y~.,data=dat,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
summary(tune.out)
bestmod=tune.out$best.model
summary(bestmod)
bestmod=tune.out$best.model
summary(bestmod)
xtest=matrix(rnorm(20*2), ncol=2)
ytest=sample(c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]=xtest[ytest==1,] + 1
testdat=data.frame(x=xtest, y=as.factor(ytest))
ypred=predict(bestmod,testdat)
table(predict=ypred, truth=testdat$y)
svmfit=svm(y~., data=dat, kernel="linear", cost=.01,scale=FALSE)
ypred=predict(svmfit,testdat)
table(predict=ypred, truth=testdat$y)
table(predict=ypred, truth=testdat$y)
x[y==1,]=x[y==1,]+0.5
plot(x, col=(y+5)/2, pch=19)
dat=data.frame(x=x,y=as.factor(y))
svmfit=svm(y~., data=dat, kernel="linear", cost=1e5)
summary(svmfit)
plot(svmfit, dat)
ypred=predict(svmfit,dat)
table(predict=ypred, truth=dat$y) # perfect training classification
svmfit=svm(y~., data=dat, kernel="linear", cost=1)
summary(svmfit)
plot(svmfit,dat)
ypred=predict(svmfit,dat)
table(predict=ypred, truth=dat$y) # one training mis-classification
set.seed(1)
x=matrix(rnorm(200*2), ncol=2)
x[1:100,]=x[1:100,]+2 # first 100 points, class 1
x[101:150,]=x[101:150,]-2 # last 50 points, class 2
y=c(rep(1,150),rep(2,50)) # first 100 class 1, last 50 class 2
dat=data.frame(x=x,y=as.factor(y))
plot(x, col=y)
train=sample(200,100) # choose 100 points randomly as training sample
svmfit=svm(y~., data=dat[train,], kernel="radial",  gamma=1, cost=1)
plot(svmfit, dat[train,])
plot(svmfit, dat[train,])
summary(svmfit)
svmfit=svm(y~., data=dat[train,], kernel="radial",gamma=1,cost=1e5)
plot(svmfit,dat[train,])
summary(svmfit)
y=c(rep(1,150),rep(2,50)) # first 100 class 1, last 50 class 2
dat=data.frame(x=x,y=as.factor(y))
plot(x, col=y)
train=sample(200,100) # choose 100 points randomly as training sample
svmfit=svm(y~., data=dat[train,], kernel="radial",  gamma=1, cost=1)
plot(svmfit, dat[train,])
summary(svmfit)
svmfit=svm(y~., data=dat[train,], kernel="radial",gamma=1,cost=1e5)
plot(svmfit,dat[train,])
summary(svmfit)
set.seed(1)
tune.out=tune(svm, y~., data=dat[train,], kernel="radial", ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
svmfit=svm(y~., data=dat[train,], kernel="radial",gamma=2,cost=1)
table(true=dat[-train,"y"], pred=predict(tune.out$best.model,newdata=dat[-train,]))
svmfit=svm(y~., data=dat[train,], kernel="polynomial", degree=2, gamma=1/2, cost=1)
plot(svmfit,dat[train,])
summary(svmfit)
ypred=predict(svmfit,testdat)
table(predict=ypred, truth=testdat$y)
install.packages("ROCR")
library(ROCR)
rocplot=function(pred, truth, ...){
predob = prediction(pred, truth)
perf = performance(predob, "tpr", "fpr")
plot(perf,...)}
svmfit.opt=svm(y~., data=dat[train,], kernel="radial",gamma=2, cost=1,decision.values=T)
fitted=attributes(predict(svmfit.opt,dat[train,],decision.values=TRUE))$decision.values
par(mfrow=c(1,2))
rocplot(fitted,dat[train,"y"],main="Training Data")
svmfit.flex=svm(y~., data=dat[train,], kernel="radial",gamma=50, cost=1, decision.values=T)
fitted=attributes(predict(svmfit.flex,dat[train,],decision.values=T))$decision.values
rocplot(fitted,dat[train,"y"],add=T,col="red")
fitted=attributes(predict(svmfit.opt,dat[-train,],decision.values=T))$decision.values
rocplot(fitted,dat[-train,"y"],main="Test Data")
svmfit.flex=svm(y~., data=dat[train,], kernel="radial",gamma=50, cost=1, decision.values=T)
fitted=attributes(predict(svmfit.opt,dat[-train,],decision.values=T))$decision.values
rocplot(fitted,dat[-train,"y"],main="Test Data")
fitted=attributes(predict(svmfit.flex,dat[-train,],decision.values=T))$decision.values
rocplot(fitted,dat[-train,"y"],add=T,col="red")
set.seed(1)
x=rbind(x, matrix(rnorm(50*2), ncol=2))
y=c(y, rep(0,50))
x[y==0,2]=x[y==0,2]+2
dat=data.frame(x=x, y=as.factor(y))
par(mfrow=c(1,1))
plot(x,col=(y+1))
svmfit=svm(y~., data=dat, kernel="radial", cost=10, gamma=1)
plot(svmfit, dat)
0.75*9 + 0.25*5
states=row.names(USArrests) # Data in base R package
states
names(USArrests)
apply(USArrests, 2, mean)
apply(USArrests, 2, var)
pr.out=prcomp(USArrests, scale=TRUE)
names(pr.out)
pr.out$center
pr.out$scale # mean and s.d. of data, as above
pr.out$rotation
apply(pr.out$rotation^2, 2, sum) # 1 because each PC has norm 1 by def
apply(pr.out$rotation^2, 1, sum) # 1 because it's a rotation matrix, a
t(pr.out$rotation) %*% pr.out$rotation
dim(pr.out$x) # Data matrix "x$ in terms of PCs instead of original "murder" etc.
biplot(pr.out, scale=0) # Mirror image of Fig 10. 1. PCs' signs arbitrary.
biplot(pr.out, scale=0) # Mirror image of Fig 10. 1. PCs' signs arbitrary.
pr.out$rotation=-pr.out$rotation # Flip PCs' signs.
pr.out$x=-pr.out$x # Flip data projections onto PCs to match.
biplot(pr.out, scale=0)
pr.out$sdev
pr.var=pr.out$sdev^2
pr.var
apply(pr.out$x,2,var)
pve=pr.var/sum(pr.var) # Proportion of Variance Explained by each PC
pve
plot(pve, xlab="Principal Component", ylab="Proportion of Variance Explained", ylim=c(0,1),type='b')
plot(cumsum(pve), xlab="Principal Component", ylab="Cumulative Proportion of Variance Explained", ylim=c(0,1),type='b')
cumsum(c(1,2,8,-3)) # silly cumsum demo
head(iris)
plot(iris[,c(1,2)],col=(iris[,5]))
pr.iris.out=prcomp(iris[,c(1,2,3,4)],scale=TRUE)
plot(pr.iris.out$x[,c(1, 2)],col=(iris[,5]))
biplot(pr.iris.out,scale=0)
rm(list=ls())
setwd("~/Desktop/MA429 Mock Project/")
install.packages("e1071")
library(e1071)
accelerometer_data <- read.table("accelerometer.csv", sep = ";", header = TRUE, dec = ",")
head(accelerometer_data)
summary(accelerometer_data)
dim(accelerometer_data)
anyNA(accelerometer_data)
install.packages("mlbench")
install.packages("caret")
library(caret)
accelerometer_data[,3:18] <- sapply(accelerometer_data[,3:18],as.numeric)
set.seed(201316007)
subset1 <- sample(165633, 5000)
accelerometer_subset <- accelerometer_data[subset1,]
set.seed(201316007)
correlationMatrix <- cor(accelerometer_data[,4:18])
print(correlationMatrix)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff = 0.5)
print(highlyCorrelated)
set.seed(201316007)
library(mlbench)
library(caret)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
model <- train(class..~., data=accelerometer_subset, method="lvq", preProcess="scale", trControl=control)
accelerometer_data[,3:18] <- sapply(accelerometer_data[,3:18],as.numeric)
set.seed(201316007)
subset1 <- sample(165633, 1000)
accelerometer_subset <- accelerometer_data[subset1,]
set.seed(201316007)
correlationMatrix <- cor(accelerometer_data[,4:18])
print(correlationMatrix)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff = 0.5)
print(highlyCorrelated)
set.seed(201316007)
library(mlbench)
library(caret)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
model <- train(class..~., data=accelerometer_subset, method="lvq", preProcess="scale", trControl=control)
importance <- varImp(model, scale=FALSE)
print(importance)
plot(importance)
set.seed(201316007)
library(mlbench)
library(caret)
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
results <- rfe(accelerometer_subset[,3:18], accelerometer_subset[,19], sizes=c(1:8), rfeControl=control)
install.packages("randomForest")
library(randomForest)
results <- rfe(accelerometer_subset[,3:18], accelerometer_subset[,19], sizes=c(1:8), rfeControl=control)
print(results)
predictors(results)
plot(results, type=c("g", "o"))
head(accelerometer_data)
set.seed(201316007)
library(mlbench)
library(caret)
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
install.packages("randomForest")
library(randomForest)
results <- rfe(accelerometer_subset[,3:18], accelerometer_subset[,19], sizes=c(3:18), rfeControl=control)
print(results)
predictors(results)
plot(results, type=c("g", "o"))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_subset)), size = floor(0.75*nrow(accelerometer_subset)))
train_set<- accelerometer_subset[split,-c(5,6)]
test_set <- accelerometer_subset[-split,-c(5,6)]
dim(train_set)
dim(test_set)
start.time <- Sys.time()
svm_fit <- svm(class..~., data=train_set, kernel = "linear",cost = 10)
end.time <- Sys.time()
end.time - start.time
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
tune.out = tune(svm, class..~., data = train_set,kernel = "linear", ranges =
list(cost = c(0.0001, 0.01, 0.1,1,5,10,20)))
summary(tune.out)
bestmod = tune.out$best.model
classpred <- predict(bestmod, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
tune.out = tune(svm, class..~., data = train_set,kernel = "polynomial", ranges =
list(cost = c(0.0001, 0.01, 0.1,1,5,10,20),degree = c(1,2,3,4,5)))
summary(tune.out)
bestmod = tune.out$best.model
classpred <- predict(bestmod, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
tune.out = tune(svm, class..~., data = train_set,kernel = "radial", ranges =
list(cost = c(0.0001, 0.01, 0.1,1,5,10,20), gamma = c(0.5,1,2,3,4)))
summary(tune.out)
bestmod = tune.out$best.model
classpred <- predict(bestmod, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6)]
test_set <- accelerometer_data[-split,-c(5,6)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 10, gamma = 0.5)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6,7,8)]
rm(list=ls())
setwd("~/Desktop/MA429 Mock Project/")
install.packages("e1071")
library(e1071)
accelerometer_data <- read.table("accelerometer.csv", sep = ";", header = TRUE, dec = ",")
head(accelerometer_data)
summary(accelerometer_data)
dim(accelerometer_data)
anyNA(accelerometer_data)
install.packages("mlbench")
library(caret)
accelerometer_data[,3:18] <- sapply(accelerometer_data[,3:18],as.numeric)
set.seed(201316007)
subset1 <- sample(165633, 1000)
accelerometer_subset <- accelerometer_data[subset1,]
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_subset)), size = floor(0.75*nrow(accelerometer_subset)))
train_set<- accelerometer_subset[split,-c(5,6,7,8)]
test_set <- accelerometer_subset[-split,-c(5,6,7,8)]
dim(train_set)
dim(test_set)
start.time <- Sys.time()
svm_fit <- svm(class..~., data=train_set, kernel = "linear",cost = 10)
end.time <- Sys.time()
end.time - start.time
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
tune.out = tune(svm, class..~., data = train_set,kernel = "linear", ranges =
list(cost = c(0.0001, 0.01, 0.1,1,5,10,20)))
summary(tune.out)
bestmod = tune.out$best.model
classpred <- predict(bestmod, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
tune.out = tune(svm, class..~., data = train_set,kernel = "polynomial", ranges =
list(cost = c(0.0001, 0.01, 0.1,1,5,10,20),degree = c(1,2,3,4,5)))
summary(tune.out)
bestmod = tune.out$best.model
classpred <- predict(bestmod, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
tune.out = tune(svm, class..~., data = train_set,kernel = "radial", ranges =
list(cost = c(0.0001, 0.01, 0.1,1,5,10,20), gamma = c(0.5,1,2,3,4)))
summary(tune.out)
bestmod = tune.out$best.model
classpred <- predict(bestmod, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 5, gamma = 0.5)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6,7,8)]
test_set <- accelerometer_data[-split,-c(5,6,7,8)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 5, gamma = 0.5)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6,7,8)]
test_set <- accelerometer_data[-split,-c(5,6,7,8)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 10, gamma = 0.5)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6,7)]
test_set <- accelerometer_data[-split,-c(5,6,7)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 10, gamma = 0.5)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5)]
test_set <- accelerometer_data[-split,-c(5)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 10, gamma = 0.5)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6)]
test_set <- accelerometer_data[-split,-c(5,6)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 10, gamma = 0.5)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6)]
test_set <- accelerometer_data[-split,-c(5,6)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 10, gamma = 1)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6)]
test_set <- accelerometer_data[-split,-c(5,6)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 10, gamma = 0.5)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6)]
test_set <- accelerometer_data[-split,-c(5,6)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 10, gamma = 0.35)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6)]
test_set <- accelerometer_data[-split,-c(5,6)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 10, gamma = 0.2)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
set.seed(201316007)
split <- sample(seq_len(nrow(accelerometer_data)), size = floor(0.75*nrow(accelerometer_data)))
train_set<- accelerometer_data[split,-c(5,6)]
test_set <- accelerometer_data[-split,-c(5,6)]
dim(train_set)
set.seed(201316007)
start.time <- Sys.time()
svm_fit = svm(class..~., data = train_set,kernel = "radial", cost = 10, gamma = 0.5)
end.time <- Sys.time()
end.time - start.time
summary(svm_fit)
classpred <- predict(svm_fit, test_set)
test_accuracy <- function(table_values){
sum(diag(table_values))/sum(table_values)
}
test_accuracy(table(predict = classpred, truth = test_set$`class..`))
